# -*- coding: utf-8 -*-
"""LehmanData Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/135QXMSx5dJFSuJlchFuKYYpwTtSPXpZb

Objective: validating satellite-based rainfall data (from NASA GPM) using ground-based observations (gauge data).

This will be done by performing a  correlation analysis and calculating R-Square.
"""

#import libraries to perform analysis
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import statsmodels.formula.api as smf #for regression thus will help calculate R-square value

ds = pd.read_excel("combined_Gauge_with_GPM_Single_and_3x3_Cell_2023-2024_Lehman.xlsx")
ds

"""# Cleaning Data"""

ds.isna().any(axis=1)

ds.dropna(inplace=True)
ds

#GPM data represents 1 hour'worth of data
#Rec simply coverts it to 30 mins by dividing by 2
#ds["Rec GPM data"] = (ds["GPM data"] / 2)
#ds

ds.describe()

"""Graph below plots the average data recorded by each variable"""

#creates a new column representing months
ds['Month'] = pd.to_datetime(ds['Row Labels']).dt.to_period('M')
ds

monthly_sum = ds.groupby('Month')[['Sum of Tips [0.254 mm]', 'GPM data single cell', 'GPM Data 3x3 cell']].sum()
monthly_sum
#Below is the total amount of rainfall per month

Lehman_tot = sns.catplot(x = 'Month', y = 'Sum of Tips [0.254 mm]', data = monthly_sum, kind = 'bar')
Lehman_tot.set_xticklabels(rotation = 90)
plt.title('Total Rainfall by Month at Lehman College')

monthly_avg = ds.groupby('Month')[['Sum of Tips [0.254 mm]', 'GPM data single cell', 'GPM Data 3x3 cell']].mean()
monthly_avg.plot(kind='line', figsize=(10, 6))
plt.title('Average Monthly Trends')
plt.xlabel('Month')
plt.ylabel('Average Value (mm)')
plt.grid(True)
plt.show()

monthly_avg

"""**Goal: Rainfall event can cover one day or two days, but it is a consecutive date range. It would be great to know which events (by date) produce the best and which events produce the worst results.
Doing this by filtering based on month column
**

#**Linear Regression:**
x = (Sum of tips) y = GPM data (GPM data single cell) or (GPM Data 3x3 cell). Since we are finding how well 2 variables correlate, it does not really matter which is x or y as they will produce the same R-Square. Example done  for July 2023.

Examining each month by filtering using "Month" column and then performing a regression analysis.

#July 2023
"""

july_23 = ds[ds['Month'] == '2023-07']
july_23

#here y = Sum of Tips and x = GPM data single cell
lm = smf.ols("Q('Sum of Tips [0.254 mm]') ~ Q('GPM data single cell')", data=july_23).fit()
lm.summary()

#how professor does it
# y = GPM data single cell & x = Sum of Tips
july_23lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data=july_23).fit()
july_23lm.summary()

july_23lm.resid

july_23lm.resid.hist(bins=20)
#residuals should have a normal distribution centered at 0

sns.regplot(x= "Sum of Tips [0.254 mm]", y = "GPM data single cell", data = july_23)
plt.title('Regression Analysis for July 2023')

july_23_reclm = smf.ols("Q('GPM Data 3x3 cell') ~ Q('Sum of Tips [0.254 mm]')", data=july_23).fit()
july_23_reclm.summary()

sns.regplot(x= "Sum of Tips [0.254 mm]", y = "GPM Data 3x3 cell", data = july_23)
plt.title('Regression Analysis for July 2023')

"""# August 2023"""

aug_23 = ds[ds['Month'] == '2023-08']
aug_23

aug_23lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data=aug_23).fit()
aug_23lm.summary()

sns.regplot(x= "Sum of Tips [0.254 mm]", y = "GPM data single cell", data = aug_23)
plt.title('Regression Analysis for August 2023')

aug_23_reclm = smf.ols("Q('GPM Data 3x3 cell') ~ Q('Sum of Tips [0.254 mm]')", data=aug_23).fit()
aug_23_reclm.summary()

sns.regplot(x= "Sum of Tips [0.254 mm]", y = "GPM Data 3x3 cell", data = aug_23)
plt.title('Regression Analysis for August 2023')

"""# September 2023"""

sept_2023 = ds[ds['Month'] == '2023-09']
sept_2023

sept_2023lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= sept_2023).fit()
sept_2023lm.summary()

sns.regplot(x= "Sum of Tips [0.254 mm]", y = "GPM data single cell", data = sept_2023)
plt.title('Regression Analysis for September 2023')

sept_23reclm = smf.ols("Q('GPM Data 3x3 cell') ~ Q('Sum of Tips [0.254 mm]')", data= sept_2023).fit()
sept_23reclm.summary()

sns.regplot(x= "Sum of Tips [0.254 mm]", y = "GPM Data 3x3 cell", data = sept_2023)
plt.title('Regression Analysis for September 2023')

"""# October 2023"""

oct_2023 = ds[ds['Month'] == '2023-10']
oct_2023

oct_2023lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= oct_2023).fit()
oct_2023lm.summary()

sns.regplot(x= "Sum of Tips [0.254 mm]", y = "GPM data single cell", data = oct_2023)
plt.title('Regression Analysis for October 2023')

"""# November 2023"""

nov_2023 = ds[ds['Month']== '2023-11']
nov_2023

nov_23lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= nov_2023).fit()
nov_23lm.summary()

sns.regplot(x= "Sum of Tips [0.254 mm]", y = "GPM data single cell", data = nov_2023)
plt.title('Regression Analysis for November 2023')

"""# December 2023"""

dec_23 = ds[ds['Month']== '2023-12']
dec_23

dec_23lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= dec_23).fit()
dec_23lm.summary()

sns.regplot(x= "Sum of Tips [0.254 mm]", y = "GPM data single cell", data = dec_23)
plt.title("Regression Analysis December 2023")

"""# January 2024"""

jan_2024 = ds[ds['Month']== '2024-01']
jan_2024

jan_2024lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= jan_2024).fit()
jan_2024lm.summary()

sns.regplot(x="Sum of Tips [0.254 mm]", y = "GPM data single cell", data = jan_2024)
plt.title("Regression Analysis January 2024")

"""# February 2024"""

feb_2024 = ds[ds['Month']== '2024-02']
feb_2024

feb_24lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= feb_2024).fit()
feb_24lm.summary()

sns.regplot(x="Sum of Tips [0.254 mm]", y = "GPM data single cell", data = feb_2024)
plt.title("Regression Analysis February 2024")

"""# March 2024

"""

march_2024 = ds[ds['Month']== '2024-03']
march_2024

mar_24lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= march_2024).fit()
mar_24lm.summary()

sns.regplot(x="Sum of Tips [0.254 mm]", y = "GPM data single cell", data = march_2024)
plt.title("Regression Analysis March 2024")

"""# April 2024"""

apr_2024 = ds[ds['Month']== '2024-04']
apr_2024

apr_24lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= apr_2024).fit()
apr_24lm.summary()

sns.regplot(x="Sum of Tips [0.254 mm]", y = "GPM data single cell", data = apr_2024)
plt.title("Regression Analysis April 2024")

"""# May 2024"""

may_24 = ds[ds['Month']== '2024-05']
may_24

may_24lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= may_24).fit()
may_24lm.summary()

sns.regplot(x="Sum of Tips [0.254 mm]", y = "GPM data single cell", data= apr_2024)
plt.title("Regression Analysis May 2024")

"""# June 2024"""

jun_2024 = ds[ds['Month'] == '2024-06']
jun_2024

jun_24lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= jun_2024).fit()
jun_24lm.summary()

sns.regplot(x="Sum of Tips [0.254 mm]", y = "GPM data single cell", data = jun_2024)
plt.title("Regression Analysis June 2024")

"""# July 2024"""

july_2024 = ds[ds['Month'] == '2024-07']
july_2024

july_24lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= july_2024).fit()
july_24lm.summary()

sns.regplot(x="Sum of Tips [0.254 mm]", y = "GPM data single cell", data = july_2024)
plt.title("Regression Analysis July 2024")

"""# August 2024"""

aug_2024 = ds[ds['Month'] == '2024-08']
aug_2024

aug_24lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= aug_2024).fit()
aug_24lm.summary()

sns.regplot(x="Sum of Tips [0.254 mm]", y = "GPM data single cell", data = aug_2024)
plt.title("Regression Analysis August 2024")

"""# September 2024"""

sept_2024 = ds[ds['Month'] == '2024-09']
sept_2024

sept_24lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= sept_2024).fit()
sept_24lm.summary()

sns.regplot(x="Sum of Tips [0.254 mm]", y = "GPM data single cell", data = sept_2024)
plt.title("Regression Analysis September 2024")

"""# October 2024"""

oct_2024 = ds[ds['Month'] == '2024-10']
oct_2024
#No october data

"""# November 2024"""

nov_2024 = ds[ds["Month"] == "2024-11"]
nov_2024

nov_24lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= nov_2024).fit()
nov_24lm.summary()

sns.regplot(x="Sum of Tips [0.254 mm]", y = "GPM data single cell", data = nov_2024)
plt.title("Regression Analysis November 2024")

"""Dataframe with each month and its corresponding R-squared."""

Rsq_values = []

for month in ds['Month'].unique():
    # Filter data for the current month
    monthly_data = ds[ds['Month'] == month]

    # Perform linear regression
    model = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data=monthly_data).fit()

    # Append the results to the list
    Rsq_values.append([month, model.rsquared])

results_df = pd.DataFrame(Rsq_values, columns=['Month', 'R-squared'])
results_df

"""# **overall** linear regression"""

lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= ds).fit()
lm.summary()

sns.regplot(x="Sum of Tips [0.254 mm]", y = "GPM data single cell", data = ds)
plt.title("Regression Analysis for Lehman College")

lm = smf.ols("Q('Sum of Tips [0.254 mm]') ~ Q('GPM data single cell')", data= ds).fit()
lm.summary()

sns.regplot(x="GPM data single cell", y = "Sum of Tips [0.254 mm]", data = ds)
plt.title("Regression Analysis for Lehman College")

sns.regplot(x="Sum of Tips [0.254 mm]", y = "GPM Data 3x3 cell", data = ds)
plt.title("Regression Analysis for Lehman College")

lm = smf.ols("Q('GPM Data 3x3 cell') ~ Q('Sum of Tips [0.254 mm]')", data= ds).fit()
lm.summary()

"""3x3 data produces a better R-Sqaure when analyzing Lehman's data in its entirety.

#Completing goal: Calculating R-squared for dates
"""

#creating a column for "Date", that groups all the dates
ds['Date'] = pd.to_datetime(ds['Row Labels']).dt.to_period('D')
ds

Daily_Rsq_values = []

for date in ds['Date'].unique():
    # Filter data for the current date
    daily_data = ds[ds['Date'] == date]

    # Perform linear regression
    daily_model = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data=daily_data).fit()

    # Append the results to the list
    Daily_Rsq_values.append([date, daily_model.rsquared])

results_df = pd.DataFrame(Daily_Rsq_values, columns=['Date', 'R-squared'])

# Set display options to show all rows and columns
#pd.set_option("display.max_rows", None, "display.max_columns", None)
results_df

output_file_path = "Daily_R-squared_values_using_single_cell.txt"
results_df.to_csv(output_file_path, index=False)

#arranging in descending order
results_df_order = results_df.sort_values(["R-squared"], ascending = False)
results_df_order

#to excel file
output_file_path = "Daily_R-squared_values_order_single_cell.xlsx"
results_df_order.to_excel(output_file_path, index=False)

#for daily pixel data
Daily_pix_Rsq_values = []

#loop that calculates the R-square and makes it for as a list
for date in ds['Date'].unique():
    # Filter data for the current date
    daily_data = ds[ds['Date'] == date]

    # Perform linear regression
    daily_pix_model = smf.ols("Q('GPM Data 3x3 cell') ~ Q('Sum of Tips [0.254 mm]')", data=daily_data).fit()

    # Append the results to the list
    Daily_pix_Rsq_values.append([date, daily_model.rsquared])

pix_results_df = pd.DataFrame(Daily_pix_Rsq_values, columns=['Date', 'R-squared'])

# Set display options to show all rows and columns
#pd.set_option("display.max_rows", None, "display.max_columns", None)
pix_results_df

#descending order
pix_results_df_order = pix_results_df.sort_values(["R-squared"], ascending = False)
pix_results_df_order

output_file_path = "Daily_R-squared_values_order_3x3_cell.xlsx"
pix_results_df_order.to_excel(output_file_path, index=False)

#creating a linear regression model that compares the sum of each date's sum of tips and gpm data
#summing dates
daily_sum = ds.groupby('Date')[['Sum of Tips [0.254 mm]', 'GPM data single cell','GPM Data 3x3 cell']].sum()
#pd.set_option("display.max_rows", None, "display.max_columns", None)
daily_sum

daily_sum_3x3_lm = smf.ols("Q('GPM Data 3x3 cell') ~ Q('Sum of Tips [0.254 mm]')", data= daily_sum).fit()
daily_sum_3x3_lm.summary()

daily_sum_sc_lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= daily_sum).fit()
daily_sum_sc_lm.summary()

sns.regplot(x="Sum of Tips [0.254 mm]",y = "GPM Data 3x3 cell" ,data = daily_sum)
#

sns.regplot(x="Sum of Tips [0.254 mm]",y = "GPM data single cell" ,data = daily_sum)
#sns.regplot(x="GPM data", y = "Sum of Tips [0.254 mm]", data = daily_sum)

"""# **Below is using filtered data for dates that see a minimum consecutive of  3 rainfall events**"""

#deleting dates within ds that do not experience 3 consecutive rainfall events
#b/c r-square requires a minimum of 2 data points

# Grouping data by 'Date' and count data points for each date
date_counts = ds.groupby('Date')['Row Labels'].count()

# Filter dates with less than 3 data points
dates_to_keep = date_counts[date_counts >= 3].index

# creating a new dataframe with dates a minimum of 3 data points
new_ds = ds[ds['Date'].isin(dates_to_keep)]
#pd.set_option("display.max_rows", None, "display.max_columns", None)

new_ds

new_ds.describe()

monthly_sum = new_ds.groupby('Month')[['Sum of Tips [0.254 mm]', 'GPM data single cell', 'GPM Data 3x3 cell']].sum()
monthly_sum

Lehman_tot = sns.catplot(x = 'Month', y = 'Sum of Tips [0.254 mm]', data = monthly_sum, kind = 'bar')
Lehman_tot.set_xticklabels(rotation = 90)
plt.title('Total Rainfall by Month at Lehman College')

monthly_avg = ds.groupby('Month')[['Sum of Tips [0.254 mm]', 'GPM data single cell', 'GPM Data 3x3 cell']].mean()
monthly_avg.plot(kind='line', figsize=(10, 6))
plt.title('Average Monthly Trends')
plt.xlabel('Month')
plt.ylabel('Average Value (mm)')
plt.grid(True)
plt.show()

monthly_avg

consecutive_Rsq_values = []

for date in new_ds['Date'].unique():
    # Filter data for the current date
    consecutive_data = new_ds[new_ds['Date'] == date] #understanding this

    # Perform linear regression
    consecutive_model = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data=consecutive_data).fit()

    # Append the results to the list
    consecutive_Rsq_values.append([date, consecutive_model.rsquared])

results_df = pd.DataFrame(consecutive_Rsq_values, columns=['Date', 'R-squared'])

# Set display options to show all rows and columns
#pd.set_option("display.max_rows", None, "display.max_columns", None)
results_df

#arranging in descending order
results_df_order = results_df.sort_values(["R-squared"], ascending = False)
results_df_order

output_file_path = "Dates_R-squared_values_order_sc_cell.xlsx"
results_df_order.to_excel(output_file_path, index=False)

date_counts=new_ds.groupby('Date')['Row Labels'].count()
date_counts

checking = consecutive_data.groupby('Date')['Row Labels'].count()
checking

#let's see if get filter for only dates with 3 consecutive 30 minute intervals with rainfall

consecutive_3x3_Rsq_values = []

for date in new_ds['Date'].unique():
    # Filter data for the current date
    consecutive_data = new_ds[new_ds['Date'] == date] #understanding this

    # Perform linear regression
    consecutive_3x3_model = smf.ols("Q('GPM Data 3x3 cell') ~ Q('Sum of Tips [0.254 mm]')", data=consecutive_data).fit()

    # Append the results to the list
    consecutive_3x3_Rsq_values.append([date, consecutive_3x3_model.rsquared])

results_3x3_df = pd.DataFrame(consecutive_3x3_Rsq_values, columns=['Date', 'R-squared'])
results_3x3_df

results_3x3_df_order = results_3x3_df.sort_values(["R-squared"], ascending = False)
results_3x3_df_order

output_file_path = "Dates_R-squared_values_order_3x3_cell.xlsx"
results_3x3_df_order.to_excel(output_file_path, index=False)

sc_lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= new_ds).fit()
sc_lm.summary()

sns.regplot(x="Sum of Tips [0.254 mm]", y = "GPM data single cell", data = new_ds)
plt.title("Regression Analysis for Lehman College")

pix_lm=smf.ols("Q('GPM Data 3x3 cell') ~ Q('Sum of Tips [0.254 mm]')", data= new_ds).fit()
pix_lm.summary()

sns.regplot(x="Sum of Tips [0.254 mm]", y = "GPM Data 3x3 cell", data = new_ds)
plt.title("Regression Analysis for Lehman College")

"""# Working with Consecutive data

how can I filter so that only 'row labels' with a minimum 3 consecutive intervals show. be mindlful that the row labels columns consists of date/timestamps; where the timestamp is a 30 minute interval
"""

# Assuming 'ds' is your DataFrame and 'Row Labels' is your column with date/timestamps

# Convert 'Row Labels' to datetime objects if not already
ds['Row Labels'] = pd.to_datetime(ds['Row Labels'])

# Group by date and get consecutive groups
groups = ds.groupby(ds['Row Labels'].dt.date)['Row Labels'].diff().ne(pd.Timedelta(minutes=30)).cumsum()
# Detailed explanation is below

# Filter groups with at least 3 consecutive intervals
consecutive_ds = ds[ds.groupby(groups)['Row Labels'].transform('size') >= 3]
pd.set_option("display.max_rows", None, "display.max_columns", None)
consecutive_ds

"""**Explanation for the code above used to filter for Rainfall event.**
  
*  ds['Row Labels'].dt.date: This extracts just the date part from each timestamp in the 'Row Labels' column. The data is then grouped by these dates.

* diff(): Within each date group, this calculates the time difference between consecutive timestamps.

* .ne(pd.Timedelta(minutes=30)): This checks if the time difference is not equal to 30 minutes. This is how we identify breaks in the 30-minute intervals. When the difference is not 30 minutes, it marks the start of a new consecutive sequence.

* .cumsum(): This performs a cumulative sum. Each time a break in the 30-minute interval is detected (where .ne() is True), the cumulative sum increases. This creates unique group identifiers for each set of consecutive 30-minute intervals within a day.

* ['Row Labels'].transform('size'): Within each of these groups, this calculates the number of rows (the 'size' of the group), effectively counting how many consecutive 30-minute intervals are in that group. The transform method ensures that this size is returned for each row in the original DataFrame, aligned with its corresponding group.


"""

output_file_path = "Rain_Event_2023-2024_Lehman_College.xlsx"
consecutive_ds.to_excel(output_file_path, index=False)

consecutive_ds.describe()

date_counts=consecutive_ds.groupby('Date')['Row Labels'].count()
#pd.set_option("display.max_rows", None, "display.max_columns", None)
date_counts

date_counts = date_counts.sort_values(ascending = False)
date_counts

monthly_con_sum = consecutive_ds.groupby('Month')[['Sum of Tips [0.254 mm]', 'GPM data single cell', 'GPM Data 3x3 cell']].sum()
monthly_con_sum

Lehman_tot = sns.catplot(x = 'Month', y = 'Sum of Tips [0.254 mm]', data = monthly_con_sum, kind = 'bar')
Lehman_tot.set_xticklabels(rotation = 90)
plt.title('Total Rainfall during Rain Events by Month at Lehman College')

monthly_con_avg = consecutive_ds.groupby('Month')[['Sum of Tips [0.254 mm]', 'GPM data single cell', 'GPM Data 3x3 cell']].mean()
monthly_con_avg.plot(kind='line', figsize=(10, 6))
plt.title('Average Monthly Trends')
plt.xlabel('Month')
plt.ylabel('Average Value (mm)')
plt.grid(True)
plt.show()

monthly_con_avg

#code below makes a list then a loop that calculates the R-squared for each date in our consecutive data
consecutive_Rsq_values = []

for date in consecutive_ds['Date'].unique():
    # Filter data for the current date
    consecutive_data = consecutive_ds[consecutive_ds['Date'] == date]
# This line filters the consecutive_ds DataFrame. It selects only the rows where the value in
# the Date column matches the current date from the loop. The resulting subset of data for that
#specific date is stored in a new DataFrame called consecutive_data.

    # Perform linear regression that calculates the R-square value
    consecutive_model = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data=consecutive_data).fit()

    # Append the results to the list
    consecutive_Rsq_values.append([date, consecutive_model.rsquared])

con_results_df = pd.DataFrame(consecutive_Rsq_values, columns=['Date', 'R-squared'])

# Set display options to show all rows and columns
#pd.set_option("display.max_rows", None, "display.max_columns", None)
con_results_df

con_results_df = con_results_df.sort_values(["R-squared"], ascending = False)
#pd.set_option("display.max_rows", None, "display.max_columns", None)
con_results_df

output_file_path = "Consecutive_Dates_R-squared_values_order_sc_cell.xlsx"
con_results_df.to_excel(output_file_path, index=False)

consec_sc_lm = smf.ols("Q('GPM data single cell') ~ Q('Sum of Tips [0.254 mm]')", data= consecutive_ds).fit()
consec_sc_lm.summary()

sns.regplot(x="Sum of Tips [0.254 mm]", y = "GPM data single cell", data = consecutive_ds)
plt.title("Regression Analysis for Lehman College")

consecutive_3x3_Rsq_values = []

for date in consecutive_ds['Date'].unique():
    # Filter data for the current date
    consecutive_data = consecutive_ds[consecutive_ds['Date'] == date] #understanding this

    # Perform linear regression
    consecutive_3x3_model = smf.ols("Q('GPM Data 3x3 cell') ~ Q('Sum of Tips [0.254 mm]')", data=consecutive_data).fit()

    # Append the results to the list
    consecutive_3x3_Rsq_values.append([date, consecutive_3x3_model.rsquared])

con_results_3x3_df = pd.DataFrame(consecutive_3x3_Rsq_values, columns=['Date', 'R-squared'])
con_results_3x3_df

con_results_3x3_df_order = results_3x3_df.sort_values(["R-squared"], ascending = False)
#pd.set_option("display.max_rows", None, "display.max_columns", None)
con_results_3x3_df_order

output_file_path = "Consecutive_Dates_R-squared_values_order_3x3_cell.xlsx"
con_results_3x3_df_order.to_excel(output_file_path, index=False)

pix_lm=smf.ols("Q('GPM Data 3x3 cell') ~ Q('Sum of Tips [0.254 mm]')", data= consecutive_ds).fit()
pix_lm.summary()

sns.regplot(x="Sum of Tips [0.254 mm]", y = "GPM Data 3x3 cell", data = consecutive_ds)
plt.title("Regression Analysis for Lehman College")